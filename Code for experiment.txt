import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import random
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.decomposition import PCA
from scipy.stats import wasserstein_distance
import hashlib
import torch.nn.functional as F

#Phase1

def configure_device():
    """
    Robust device configuration with CUDA support
    
    Returns:
        tuple: Configured device and generator
    """
    if torch.cuda.is_available():
        device = torch.device("cuda")
        
        torch.cuda.set_device(0)  # Use first GPU if multiple are available
        cuda_generator = torch.Generator(device='cuda')
        cuda_generator.manual_seed(42)
        
        torch.backends.cudnn.benchmark = False
        torch.backends.cudnn.deterministic = True
    else:
        device = torch.device("cpu")
        cuda_generator = torch.Generator()
    
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    return device, cuda_generator

device, cuda_generator = configure_device()
print(f"Using device: {device}")

if torch.cuda.is_available():
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

class DatasetPreparation:
    @staticmethod
    def get_cifar10_dataset(num_users=100, non_iid_alpha=0.1):
        """
        Prepare CIFAR-10 dataset with controlled non-IID distribution
        
        Args:
            num_users (int): Total number of users to split the dataset
            non_iid_alpha (float): Dirichlet distribution parameter for non-IID split
        
        Returns:
            dict: Dictionary of user-specific data with controlled distribution
        """
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        
        trainset = torchvision.datasets.CIFAR10(
            root='./data', train=True, download=True, transform=transform
        )
        
        class_indices = {}
        for idx, (_, label) in enumerate(trainset):
            if label not in class_indices:
                class_indices[label] = []
            class_indices[label].append(idx)
        
        class_distribution = np.random.dirichlet(
            [non_iid_alpha] * len(class_indices), 
            num_users
        )
        
        user_datasets = {}
        for i in range(num_users):
            user_indices = []
            for label, indices in class_indices.items():
                # Compute number of samples for this label for the current user
                num_samples = int(class_distribution[i][label] * len(indices))
                user_label_indices = np.random.choice(
                    indices, num_samples, replace=False
                )
                user_indices.extend(user_label_indices)
            
            user_subset = torch.utils.data.Subset(trainset, user_indices)
            user_loader = torch.utils.data.DataLoader(
                user_subset, 
                batch_size=32, 
                shuffle=True, 
                generator=cuda_generator
            )
            
            user_datasets[f'user_{i}'] = user_subset
        
        return user_datasets

class TrapModel(nn.Module):
    def __init__(self, input_dim=3072, num_classes=10):
        """
        Neural Network with Trap Weights
        
        Args:
            input_dim (int): Flattened input dimension
            num_classes (int): Number of classes (+1 for adversarial)
        """
        super(TrapModel, self).__init__()
        
        self.fc1 = nn.Linear(input_dim, 1000)
        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')
        
        self.fc2 = nn.Linear(1000, 500)
        self.fc3 = nn.Linear(500, 250)
        self.fc4 = nn.Linear(250, 100)
        
        self.fc5 = nn.Linear(100, num_classes + 1)
        
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = x.view(x.size(0), -1)  
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        x = self.relu(self.fc4(x))
        x = self.fc5(x)
        return x

def inject_sybil_users(users, user_datasets, sybil_fraction=0.3):
    """
    Inject Sybil users with controlled gradient characteristics
    
    Args:
        users (list): Original user list
        user_datasets (dict): User datasets
        sybil_fraction (float): Fraction of Sybil users
    
    Returns:
        list: Updated user list with Sybil users
    """
    num_sybil = int(len(users) * sybil_fraction)
    sybil_users = []
    
    for i in range(num_sybil):
        # In inject_sybil_users():
        # Create Sybil data directly on GPU
        zero_data = torch.zeros(1, 3, 32, 32).to(device)  # Add device placement
        zero_label = torch.zeros(1, dtype=torch.long).to(device)
        
        # Create a minimal dataset with zero/constant data
        zero_dataset = torch.utils.data.TensorDataset(zero_data, zero_label)
        
        sybil_users.append({
            'is_sybil': True, 
            'data': zero_dataset,
            'identifier': f'sybil_{i}'
        })
    
    return users + sybil_users

def manipulate_gradients(model, sybil_users):
    """
    Advanced gradient manipulation for Sybil users
    
    Args:
        model (nn.Module): Neural network model
        sybil_users (list): List of Sybil users
    """
    for user in sybil_users:
        if user.get('is_sybil', False):
            # More sophisticated gradient manipulation
            # 1. Freeze first layer completely
            model.fc1.weight.requires_grad = False
            model.fc1.bias.requires_grad = False
            
            # 2. Inject bias towards specific classes
            # This simulates a more advanced attack vector
            model.fc5.bias.data += torch.randn_like(model.fc5.bias.data) * 0.1

def main():
    # Hyperparameters
    NUM_USERS = 100
    USERS_PER_ROUND = 10
    SYBIL_FRACTION = 0.3
    NON_IID_ALPHA = 0.1
    
    user_datasets = DatasetPreparation.get_cifar10_dataset(
        NUM_USERS, 
        non_iid_alpha=NON_IID_ALPHA
    )
    
    model = TrapModel().to(device)
    
    users = list(user_datasets.keys())
    users_with_sybils = inject_sybil_users(
        users, 
        user_datasets, 
        SYBIL_FRACTION
    )
    
    manipulate_gradients(model, [
        {'is_sybil': True} for _ in range(int(NUM_USERS * SYBIL_FRACTION))
    ])

if __name__ == "__main__":
    main()

print("Enhanced Baseline Experiment Setup Completed Successfully!")


#Phase2
class EnhancedPrivacyMechanism:
    def __init__(self, base_noise_scale=0.1, num_users=100, device=torch.device('cuda')):
        """
        Enhanced Privacy Mechanism with Device Awareness
        
        Args:
            base_noise_scale (float): Base differential privacy noise scale
            num_users (int): Total number of users in the FL setup
            device (torch.device): Computational device
        """
        self.base_noise_scale = base_noise_scale
        self.num_users = num_users
        self.device = device
        self.global_gradient_history = []
        self.sybil_detection_threshold = 0.7
        
        self.detection_metrics = {
            'update_distances': [],
            'gradient_norms': []
        }

    def adaptive_noise_scale(self, grad_norm):
        """
        Dynamically adapt noise scale based on gradient characteristics

        Args:
            grad_norm (float): Norm of the aggregated gradients

        Returns:
            float: Adaptive noise scale
        """
        base_noise = self.base_noise_scale
        adaptive_sigma = base_noise * (1 + torch.log1p(grad_norm))
        
        return torch.clamp(adaptive_sigma, min=0.01, max=1.0)

    def gradient_sanitizer(self, gradients):
        """
        Enhanced gradient sanitization with multiple techniques
        
        Args:
            gradients (torch.Tensor): Input gradients

        Returns:
            torch.Tensor: Sanitized gradients
        """
        clipped_grads = torch.clamp(gradients, -1.0, 1.0)
        
        noise = torch.normal(
            mean=0, 
            std=self.base_noise_scale, 
            size=clipped_grads.shape
        ).to(clipped_grads.device)
        
        sanitized_grads = torch.round(
            clipped_grads * 100 + noise
        ) / 100
        
        return sanitized_grads

    def advanced_sybil_detection(self, user_updates):
        """
        Robust multi-dimensional Sybil user detection with GPU optimization
        """
        try:
            if not user_updates:
                return []
            
            if not all(isinstance(u, dict) for u in user_updates):
                raise ValueError("Invalid updates format")
            
            grad_matrix = []
            reference_keys = sorted(user_updates[0].keys())  # Get consistent parameter order
        
            for update in user_updates:
                flat_update = torch.cat([
                    update[k].view(-1).to(device, non_blocking=True)
                    for k in reference_keys
                ])
                grad_matrix.append(flat_update)
        
            max_length = max(t.numel() for t in grad_matrix)
            grad_matrix = torch.stack([
                F.pad(t, (0, max_length - t.numel()), value=0) 
                for t in grad_matrix
            ])
        
            U, S, V = torch.pca_lowrank(grad_matrix, q=2)
            transformed_grads = torch.matmul(grad_matrix, V[:, :2])
        
            centroid = torch.mean(grad_matrix, dim=0)
            distances = torch.norm(grad_matrix - centroid, dim=1)
        
            distances_sorted, _ = torch.sort(distances)
            n = distances.size(0)
            Q1_idx, Q3_idx = n // 4, 3 * n // 4
            Q1, Q3 = distances_sorted[Q1_idx], distances_sorted[Q3_idx]
        
            threshold = Q3 + 1.5 * (Q3 - Q1)
            anomalies = (distances > threshold)
        
            sybil_indices = torch.nonzero(anomalies).flatten().cpu().numpy()
        
            return sybil_indices.tolist()
    
        except Exception as e:
            print(f"Sybil detection error: {str(e)[:200]}")
            return []

    def trap_weight_neutralization(self, model):
        """
        Advanced trap weight neutralization with robust handling
        
        Args:
            model (nn.Module): Neural network model
        
        Returns:
            nn.Module: Model with neutralized trap weights
        """
        try:
            first_layer = model.fc1.weight.data.cpu().numpy()
            
            try:
                U, S, Vt = np.linalg.svd(first_layer, full_matrices=False)
            except:
                U, S, Vt = np.linalg.svd(first_layer + 1e-8 * np.eye(first_layer.shape[0]), full_matrices=False)
            
            sv_mean = np.mean(S)
            sv_std = np.std(S)
            
            row_mask = (np.abs(U) > 0.95).any(axis=1)  # Row-wise check
            neutralization_mask = (
                (np.abs(first_layer) > sv_mean + 2 * sv_std) | 
                row_mask[:, np.newaxis]  # Broadcast mask
            )
            
            first_layer[neutralization_mask] = 0
            
            row_norms = np.linalg.norm(first_layer, axis=1, keepdims=True)
            row_norms[row_norms == 0] = 1  # Prevent division by zero
            normalized_layer = first_layer / row_norms
            
            model.fc1.weight.data = torch.from_numpy(normalized_layer).float().to(model.fc1.weight.device)
            
            return model
        
        except Exception as e:
            print(f"Trap weight neutralization error: {e}")
            return model

    def secure_aggregation_plus(self, user_models):
        """
        Enhanced Secure Aggregation with Multi-Layer Integrity Verification
        
        Args:
            user_models (list): List of user model parameters
        
        Returns:
            torch.Tensor: Aggregated and verified model parameters
        """
        model_hashes = [
            hashlib.sha256(
                str(model.state_dict()).encode()
            ).hexdigest() for model in user_models
        ]
        
        unique_hashes = set(model_hashes)
        hash_consistency_ratio = len(unique_hashes) / len(model_hashes)
        
        if hash_consistency_ratio > 0.3:
            print("Warning: Potential model tampering detected!")
        
        aggregated_model = user_models[0]
        for param_name in aggregated_model.state_dict():
            param_values = [
                model.state_dict()[param_name]
                for model in user_models
            ]
            
            valid_params = [
                param for param in param_values 
                if torch.all(torch.isfinite(param))
            ]
            
            aggregated_model.state_dict()[param_name] = torch.mean(
                torch.stack(valid_params), dim=0
            )
        
        return aggregated_model

class ExperimentalGroups:
    def __init__(self, base_model, dataset):
        """
        Setup experimental groups for comparison

        Args:
            base_model (nn.Module): Base neural network model
            dataset (torch.utils.data.Dataset): Training dataset
        """
        self.baseline_config = {
            'noise_scale': 0.1,
            'sanitization': False,
            'sybil_detection': False
        }

        self.proposed_config = {
            'noise_scale': 'adaptive',
            'sanitization': True,
            'sybil_detection': True
        }

        self.control_config = {
            'noise_scale': 0,
            'sanitization': False,
            'sybil_detection': False
        }

class MetricsTracker:
    def __init__(self):
        """
        Track and compare experimental metrics
        """
        self.metrics = {
            'reconstruction_snr': [],
            'attack_success_rate': [],
            'model_accuracy': [],
            'training_time': []
        }

    def update_metrics(self, metric_name, value):
        """
        Update specific metric

        Args:
            metric_name (str): Name of the metric
            value (float): Metric value
        """
        self.metrics[metric_name].append(value)

    def get_summary(self):
        """
        Compute metric summaries

        Returns:
            dict: Summary statistics
        """
        return {
            k: {
                'mean': np.mean(v),
                'std': np.std(v)
            } for k, v in self.metrics.items()
        }

def main():
    privacy_mechanism = EnhancedPrivacyMechanism()
    
    print("Advanced Privacy Mechanisms Initialized Successfully!")

if __name__ == "__main__":
    main()

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import random
import matplotlib.pyplot as plt
from scipy import stats

class FederatedLearningExperiment:
    def __init__(self, num_users=100, users_per_round=10, num_rounds=100):
        """
        Comprehensive Federated Learning Experiment Setup with Enhanced Metrics

        Args:
            num_users (int): Total number of users
            users_per_round (int): Number of users selected per round
            num_rounds (int): Total training rounds
        """
        print(f"Initializing Federated Learning Experiment...")
        print(f"Configuration: {num_users} users, {users_per_round} users/round, {num_rounds} rounds")

        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

        self.num_users = num_users
        self.users_per_round = users_per_round
        self.num_rounds = num_rounds
        self.device = device
        self.generator = cuda_generator

        print("Preparing Dataset...")
        self.user_datasets = DatasetPreparation.get_cifar10_dataset(num_users)
        print(f"Dataset prepared with {len(self.user_datasets)} user-specific datasets")

        self.privacy_mechanism = EnhancedPrivacyMechanism(
            base_noise_scale=0.1,
            num_users=num_users,
            device=self.device
        )

        self.metrics_tracker = MetricsTracker()

        self.experiment_types = {
            'baseline': {
                'noise_scale': 0.1,
                'sanitization': False,
                'sybil_detection': False
            },
            'proposed': {
                'noise_scale': 'adaptive',
                'sanitization': True,
                'sybil_detection': True
            }
        }

        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        self.testset = torchvision.datasets.CIFAR10(
            root='./data', train=False, download=True, transform=transform
        )
        self.test_loader = torch.utils.data.DataLoader(
            self.testset, batch_size=100, shuffle=False
        )

    def train_local_model(self, global_model, user_data, experiment_type='baseline'):
        """
        Local model training with advanced privacy mechanisms

        Args:
            global_model (nn.Module): Global model to be fine-tuned
            user_data (torch.utils.data.Dataset): User-specific dataset
            experiment_type (str): 'baseline' or 'proposed'

        Returns:
            dict: Local model updates and additional metadata
        """
        local_model = TrapModel().to(device)
        local_model.load_state_dict(global_model.state_dict())

        optimizer = optim.SGD(local_model.parameters(), lr=0.01, momentum=0.9)
        criterion = nn.CrossEntropyLoss()

        def custom_collate(batch):
            # Move data to CPU first, then to GPU if needed
            images = torch.stack([item[0] for item in batch])
            labels = torch.tensor([item[1] for item in batch])
            return images, labels

        data_loader = torch.utils.data.DataLoader(
            user_data,
            batch_size=32,
            shuffle=True,
            collate_fn=custom_collate,
            pin_memory=False  # Disable pin memory to avoid issues
        )

        config = self.experiment_types[experiment_type]
        noise_scale = config['noise_scale']

        if noise_scale == 'adaptive':
            noise_scale = float(self.privacy_mechanism.adaptive_noise_scale(
                torch.norm(torch.cat([p.view(-1) for p in local_model.parameters()]))
            ))

        local_model.train()
        local_accuracy = 0
        total_samples = 0

        for epoch in range(3):
            batch_accuracies = []
            for batch_x, batch_y in data_loader:
                batch_x, batch_y = batch_x.to(device), batch_y.to(device)

                optimizer.zero_grad()
                outputs = local_model(batch_x)
                loss = criterion(outputs, batch_y)
                loss.backward()

                if config['sanitization']:
                    for param in local_model.parameters():
                        if param.grad is not None:
                            param.grad = self.privacy_mechanism.gradient_sanitizer(param.grad)

                if noise_scale > 0:
                    for param in local_model.parameters():
                        if param.grad is not None:
                            noise = torch.zeros_like(param.grad).normal_(
                                mean=0, std=noise_scale
                            )
                            param.grad += noise

                optimizer.step()

                with torch.no_grad():
                    _, predicted = torch.max(outputs, 1)
                    batch_acc = (predicted == batch_y).float().mean().item()
                    batch_accuracies.append(batch_acc)

                    local_accuracy += (predicted == batch_y).sum().item()
                    total_samples += batch_y.size(0)

        local_accuracy /= total_samples

        local_update = {
            'update': {
                name: local_model.state_dict()[name] - global_model.state_dict()[name]
                for name in global_model.state_dict()
            },
            'local_accuracy': local_accuracy,
            'num_samples': total_samples
        }

        return local_update

    def aggregate_updates(self, local_updates, experiment_type='baseline'):
        """
        Advanced update aggregation with Sybil detection

        Args:
            local_updates (list): List of local model updates
            experiment_type (str): 'baseline' or 'proposed'

        Returns:
            dict: Aggregated update with Sybil detection metadata
        """
        config = self.experiment_types[experiment_type]
        
        update_matrix = [update['update'] for update in local_updates]  # Keep on GPU

        sybil_indices = []
        if config['sybil_detection']:
            try:
                sybil_indices = self.privacy_mechanism.advanced_sybil_detection(update_matrix)
                print(f"Detected {len(sybil_indices)} potential Sybil users")
            except Exception as e:
                print(f"Sybil detection error: {e}")

        cleaned_updates = [
            update for i, update in enumerate(local_updates)
            if i not in sybil_indices
        ]

        aggregated_update = {}
        for key in update_matrix[0].keys():
            aggregated_update[key] = torch.mean(
                torch.stack([update['update'][key] for update in cleaned_updates]),
                dim=0
            )

        return {
            'aggregated_update': aggregated_update,
            'sybil_detected': len(sybil_indices),
            'total_updates': len(local_updates)
        }

    def test_accuracy(self, model):
        """
        Realistic model accuracy testing on CIFAR-10 test set

        Args:
            model (nn.Module): Trained model

        Returns:
            float: Actual model accuracy
        """
        model.eval()
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in self.test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        return correct / total

    def calculate_reconstruction_snr(self, model):
        """
        Compute Signal-to-Noise Ratio for potential data reconstruction

        Args:
            model (nn.Module): Trained model

        Returns:
            float: Reconstruction Signal-to-Noise Ratio
        """

        try:
            random_inputs = torch.randn(10, 3, 32, 32).to(device)

            activations = []
            def hook_fn(module, input, output):
                activations.append(output.detach())

            hook = model.fc1.register_forward_hook(hook_fn)

            model(random_inputs)

            hook.remove()

            if activations:
                layer_output = activations[0]
                signal_power = torch.mean(layer_output ** 2)
                noise_power = torch.var(layer_output, unbiased=False)

                eps = 1e-8
                snr = 10 * torch.log10(signal_power / (noise_power + eps))
                snr = torch.where(torch.isfinite(snr), snr, torch.tensor(0.0).to(device))
                return torch.clamp(snr, min=-50, max=100).item()

            return 0

        except Exception as e:
            print(f"SNR calculation error: {str(e)[:200]}")
            return 0

    def federated_training(self, experiment_type='baseline'):
        """
        Federated Learning Training Process with Enhanced Tracking

        Args:
            experiment_type (str): 'baseline' or 'proposed'

        Returns:
            dict: Comprehensive experiment metrics
        """
        global_model = TrapModel().to(device)

        metrics = {
            'global_accuracy': [],
            'reconstruction_snr': [],
            'sybil_detected': [],
            'local_accuracies': [],
            'total_sybil_count': 0
        }

        users = [
            {'is_sybil': random.random() < 0.3, 'data': dataset}
            for dataset in list(self.user_datasets.values())
        ]

        print(f"Starting {experiment_type.capitalize()} Experiment Training...")
        for round in range(self.num_rounds):
            print(f"Round {round + 1}/{self.num_rounds}")

            selected_users = random.sample(users, self.users_per_round)

            local_updates = []
            local_accuracies = []
            for user in selected_users:
                update = self.train_local_model(
                    global_model,
                    user['data'],
                    experiment_type
                )
                local_updates.append(update)
                local_accuracies.append(update['local_accuracy'])

            aggregation_result = self.aggregate_updates(
                local_updates,
                experiment_type
            )

            for name, param in global_model.state_dict().items():
                global_model.state_dict()[name] += aggregation_result['aggregated_update'][name]

            if experiment_type == 'proposed':
                global_model = self.privacy_mechanism.trap_weight_neutralization(global_model)

            metrics['global_accuracy'].append(self.test_accuracy(global_model))
            metrics['reconstruction_snr'].append(
                self.calculate_reconstruction_snr(global_model)
            )
            metrics['sybil_detected'].append(aggregation_result['sybil_detected'])
            metrics['local_accuracies'].append(np.mean(local_accuracies))
            metrics['total_sybil_count'] += aggregation_result['sybil_detected']

        print(f"{experiment_type.capitalize()} Experiment Training Completed.")
        return metrics

    def visualize_results(self, baseline_metrics, proposed_metrics):
        """
        Comprehensive visualization of experimental results

        Args:
            baseline_metrics (dict): Baseline experiment metrics
            proposed_metrics (dict): Proposed method metrics
        """
        plt.figure(figsize=(20, 10))

        plt.subplot(2, 3, 1)
        plt.plot(baseline_metrics['global_accuracy'], label='Baseline')
        plt.plot(proposed_metrics['global_accuracy'], label='Proposed')
        plt.title('Global Model Accuracy')
        plt.legend()

        plt.subplot(2, 3, 2)
        plt.plot(baseline_metrics['reconstruction_snr'], label='Baseline')
        plt.plot(proposed_metrics['reconstruction_snr'], label='Proposed')
        plt.title('Reconstruction Signal-to-Noise Ratio')
        plt.legend()

        plt.subplot(2, 3, 3)
        plt.plot(baseline_metrics['sybil_detected'], label='Baseline Sybil')
        plt.plot(proposed_metrics['sybil_detected'], label='Proposed Sybil')
        plt.title('Sybil Users Detected per Round')
        plt.legend()

        plt.subplot(2, 3, 4)
        plt.plot(baseline_metrics['local_accuracies'], label='Baseline')
        plt.plot(proposed_metrics['local_accuracies'], label='Proposed')
        plt.title('Local Model Accuracies')
        plt.legend()

        plt.subplot(2, 3, 5)
        plt.bar(['Baseline', 'Proposed'],
                [baseline_metrics['total_sybil_count'],
                 proposed_metrics['total_sybil_count']])
        plt.title('Total Sybil Users Detected')

        plt.tight_layout()
        plt.show()

    def statistical_significance(self, baseline_metrics, proposed_metrics):
        """
        Advanced statistical significance testing

        Args:
            baseline_metrics (dict): Baseline experiment metrics
            proposed_metrics (dict): Proposed method metrics

        Returns:
            dict: Comprehensive statistical analysis
        """
        baseline_acc = np.array(baseline_metrics['global_accuracy'])
        proposed_acc = np.array(proposed_metrics['global_accuracy'])
    
        baseline_acc = np.round(baseline_acc, 6)
        proposed_acc = np.round(proposed_acc, 6)

        try:
            acc_test = stats.wilcoxon(baseline_acc, proposed_acc)
        except Exception as e:
            print(f"Statistical test error: {str(e)[:200]}")
            acc_test = (np.nan, np.nan)

        tests = {
            'Accuracy': acc_test,
            'Reconstruction SNR': stats.ttest_ind(
                np.round(baseline_metrics['reconstruction_snr'], 6),
                np.round(proposed_metrics['reconstruction_snr'], 6)
            ),
            'Local Accuracies': stats.ttest_ind(
                np.round(baseline_metrics['local_accuracies'], 6),
                np.round(proposed_metrics['local_accuracies'], 6)
            )
        }

        return {
            'test_results': tests,
            'summary': {
                'Total Baseline Sybil': baseline_metrics['total_sybil_count'],
                'Total Proposed Sybil': proposed_metrics['total_sybil_count']
            }
        }

def main():
    print("Starting Federated Learning Experiment")

    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)

    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
        torch.cuda.manual_seed_all(42)

    experiment = FederatedLearningExperiment(
        num_users=100,
        users_per_round=10,
        num_rounds=100
    )

    print("Running Baseline Experiment...")
    baseline_metrics = experiment.federated_training(
        experiment_type='baseline'
    )

    torch.cuda.empty_cache()

    print("Running Proposed Method Experiment...")
    proposed_metrics = experiment.federated_training(
        experiment_type='proposed'
    )

    print("Visualizing Results...")
    experiment.visualize_results(baseline_metrics, proposed_metrics)

    significance_results = experiment.statistical_significance(
        baseline_metrics,
        proposed_metrics
    )

    for test_name, (t_stat, p_value) in significance_results['test_results'].items():
        print(f"{test_name} Test:")
        print(f"  T-Statistic: {t_stat}")
        print(f"  P-Value: {p_value}")

    print("\nSybil Detection Summary:")
    print(significance_results['summary'])

    print("Experiment Completed Successfully!")

if __name__ == "__main__":
    main()

print("Experimental Workflow Initialized Successfully!")
